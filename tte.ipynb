{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Required Libraries\n",
    "Import necessary libraries including numpy, pandas, statsmodels, scipy, and matplotlib. Define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import gettempdir\n",
    "import pickle\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Union, Callable, Any\n",
    "import warnings\n",
    "\n",
    "# Define helper functions\n",
    "def glm_logit(save_path=None):\n",
    "    \"\"\"Create a logistic model fitter function\"\"\"\n",
    "    def fit_func(data, formula):\n",
    "        # Implementation would use statsmodels to fit logistic regression\n",
    "        return {\"type\": \"glm_logit\", \"formula\": formula}\n",
    "    \n",
    "    return fit_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Implementation\n",
    "Define `TrialSequence` class that handles both Per-Protocol (PP) and Intention-to-Treat (ITT) analyses with all required methods: initialization, data setting, weight model configuration, weight calculation, trial expansion, MSM fitting, prediction generation, and survival curve plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TrialSequence class\n",
    "class TrialSequence:\n",
    "    \"\"\"Python implementation of the R TrialEmulation package's trial_sequence class\"\"\"\n",
    "    \n",
    "    def __init__(self, estimand=\"PP\"):\n",
    "        \"\"\"Initialize a trial sequence with specified estimand\"\"\"\n",
    "        if estimand not in [\"PP\", \"ITT\"]:\n",
    "            raise ValueError(\"Estimand must be either 'PP' or 'ITT'\")\n",
    "            \n",
    "        self.estimand = estimand\n",
    "        self.data = None\n",
    "        self.id_col = None\n",
    "        self.period_col = None \n",
    "        self.treatment_col = None\n",
    "        self.outcome_col = None\n",
    "        self.eligible_col = None\n",
    "        self.censor_col = None\n",
    "        self.censor_weights = None\n",
    "        self.switch_weights = None\n",
    "        self.expansion = None\n",
    "        self.expansion_options = {\"chunk_size\": 500, \"censor_at_switch\": True}\n",
    "        self.outcome_model = None\n",
    "        self.msm = None\n",
    "        self.predictions = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"String representation of the trial sequence object\"\"\"\n",
    "        n_obs = 0 if self.data is None else len(self.data)\n",
    "        n_patients = 0 if self.data is None else self.data[self.id_col].nunique() if self.id_col else 0\n",
    "        \n",
    "        return f\"Trial Sequence Object\\nEstimand: {self.estimand}\\n\\nData:\\n- N: {n_obs} observations from {n_patients} patients\"\n",
    "    \n",
    "    def set_data(self, data, id=\"id\", period=\"period\", treatment=\"treatment\", \n",
    "                outcome=\"outcome\", eligible=\"eligible\"):\n",
    "        \"\"\"Set the data for the trial sequence\"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.id_col = id \n",
    "        self.period_col = period\n",
    "        self.treatment_col = treatment\n",
    "        self.outcome_col = outcome\n",
    "        self.eligible_col = eligible\n",
    "        return self\n",
    "    \n",
    "    def set_switch_weight_model(self, numerator=None, denominator=None, pool_models=\"none\", model_fitter=None):\n",
    "        \"\"\"Set up the weight model for treatment switching\"\"\"\n",
    "        if self.estimand == \"ITT\":\n",
    "            raise ValueError(\"Switch weight models cannot be used with ITT estimand\")\n",
    "            \n",
    "        # Default formulas if not provided\n",
    "        if numerator is None:\n",
    "            numerator = \"age\"\n",
    "        if denominator is None:\n",
    "            denominator = \"age + x1 + x3\"\n",
    "            \n",
    "        self.switch_weights = {\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"pool_models\": pool_models,\n",
    "            \"model_fitter\": model_fitter or glm_logit(),\n",
    "            \"fitted\": False,\n",
    "            \"weights\": None\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def set_censor_weight_model(self, censor_event, numerator=None, denominator=None, \n",
    "                               pool_models=\"none\", model_fitter=None):\n",
    "        \"\"\"Set up the weight model for informative censoring\"\"\"\n",
    "        # Default formulas if not provided\n",
    "        if numerator is None:\n",
    "            numerator = \"x2\"\n",
    "        if denominator is None:\n",
    "            denominator = \"x2 + x1\"\n",
    "            \n",
    "        self.censor_weights = {\n",
    "            \"censor_event\": censor_event,\n",
    "            \"numerator\": numerator,\n",
    "            \"denominator\": denominator,\n",
    "            \"pool_models\": pool_models,\n",
    "            \"model_fitter\": model_fitter or glm_logit(),\n",
    "            \"fitted\": False,\n",
    "            \"weights\": None\n",
    "        }\n",
    "        self.censor_col = censor_event\n",
    "        return self\n",
    "    \n",
    "    def calculate_weights(self):\n",
    "        \"\"\"Calculate weights based on the specified models\"\"\"\n",
    "        data = self.data.copy()\n",
    "        \n",
    "        # Calculate switch weights if specified (only for PP estimand)\n",
    "        if self.switch_weights and self.estimand == \"PP\":\n",
    "            # Fit logistic regression for numerator model\n",
    "            num_formula = self.switch_weights[\"numerator\"]\n",
    "            X_num = sm.add_constant(data[num_formula.split(\" + \")])\n",
    "            y_switch = data[self.treatment_col]\n",
    "            \n",
    "            num_model = Logit(y_switch, X_num).fit(disp=0)\n",
    "            num_probs = num_model.predict()\n",
    "            \n",
    "            # Fit logistic regression for denominator model\n",
    "            denom_formula = self.switch_weights[\"denominator\"]\n",
    "            X_denom = sm.add_constant(data[denom_formula.split(\" + \")])\n",
    "            \n",
    "            denom_model = Logit(y_switch, X_denom).fit(disp=0)\n",
    "            denom_probs = denom_model.predict()\n",
    "            \n",
    "            # Calculate switch weights\n",
    "            switch_weights = np.where(\n",
    "                data[self.treatment_col] == 1,\n",
    "                num_probs / np.maximum(denom_probs, 1e-10),\n",
    "                (1 - num_probs) / np.maximum(1 - denom_probs, 1e-10)\n",
    "            )\n",
    "            \n",
    "            self.switch_weights[\"fitted\"] = True\n",
    "            self.switch_weights[\"weights\"] = switch_weights\n",
    "            data['switch_weight'] = switch_weights\n",
    "        else:\n",
    "            data['switch_weight'] = 1.0\n",
    "        \n",
    "        # Calculate censoring weights if specified\n",
    "        if self.censor_weights:\n",
    "            # Fit logistic regression for numerator model\n",
    "            num_formula = self.censor_weights[\"numerator\"]\n",
    "            X_num = sm.add_constant(data[num_formula.split(\" + \")])\n",
    "            y_censor = data[self.censor_col]\n",
    "            \n",
    "            num_model = Logit(y_censor, X_num).fit(disp=0)\n",
    "            num_probs = num_model.predict()\n",
    "            \n",
    "            # Fit logistic regression for denominator model\n",
    "            denom_formula = self.censor_weights[\"denominator\"]\n",
    "            X_denom = sm.add_constant(data[denom_formula.split(\" + \")])\n",
    "            \n",
    "            denom_model = Logit(y_censor, X_denom).fit(disp=0)\n",
    "            denom_probs = denom_model.predict()\n",
    "            \n",
    "            # Calculate censoring weights\n",
    "            censor_weights = np.where(\n",
    "                data[self.censor_col] == 1,\n",
    "                num_probs / np.maximum(denom_probs, 1e-10),\n",
    "                (1 - num_probs) / np.maximum(1 - denom_probs, 1e-10)\n",
    "            )\n",
    "            \n",
    "            self.censor_weights[\"fitted\"] = True\n",
    "            self.censor_weights[\"weights\"] = censor_weights\n",
    "            data['censor_weight'] = censor_weights\n",
    "        else:\n",
    "            data['censor_weight'] = 1.0\n",
    "            \n",
    "        # Calculate combined weights\n",
    "        data['total_weight'] = data['switch_weight'] * data['censor_weight']\n",
    "        self.data = data\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_outcome_model(self, adjustment_terms=None):\n",
    "        \"\"\"Set the outcome model specification\"\"\"\n",
    "        self.outcome_model = {\n",
    "            \"adjustment_terms\": adjustment_terms\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def set_expansion_options(self, output=None, chunk_size=500, censor_at_switch=True):\n",
    "        \"\"\"Set options for expanding trials\"\"\"\n",
    "        self.expansion_options = {\n",
    "            \"output\": output or \"dataframe\",\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"censor_at_switch\": censor_at_switch\n",
    "        }\n",
    "        return self\n",
    "    \n",
    "    def expand_trials(self):\n",
    "        \"\"\"Expand the dataset into a sequence of trials\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Data must be set before expanding trials\")\n",
    "            \n",
    "        # Create expanded dataset\n",
    "        data = self.data\n",
    "        \n",
    "        # Get unique periods for trials\n",
    "        unique_periods = sorted(data[self.period_col].unique())\n",
    "        max_period = max(unique_periods)\n",
    "        \n",
    "        expanded_data = []\n",
    "        \n",
    "        # For each trial period\n",
    "        for trial_period in unique_periods[:-1]:  # Exclude the last period as a trial start\n",
    "            # Filter eligible patients at trial start\n",
    "            eligible_patients = data[\n",
    "                (data[self.period_col] == trial_period) & \n",
    "                (data[self.eligible_col] == 1)\n",
    "            ][self.id_col].unique()\n",
    "            \n",
    "            if len(eligible_patients) == 0:\n",
    "                continue\n",
    "                \n",
    "            # For each eligible patient\n",
    "            for patient_id in eligible_patients:\n",
    "                patient_data = data[data[self.id_col] == patient_id]\n",
    "                \n",
    "                # Get treatment status at trial start\n",
    "                initial_treatment = patient_data[\n",
    "                    patient_data[self.period_col] == trial_period\n",
    "                ][self.treatment_col].values[0]\n",
    "                \n",
    "                # For each follow-up period\n",
    "                for followup in range(1, max_period - trial_period + 1):\n",
    "                    current_period = trial_period + followup\n",
    "                    \n",
    "                    # Check if we have data for this follow-up period\n",
    "                    if current_period not in patient_data[self.period_col].values:\n",
    "                        continue\n",
    "                    \n",
    "                    # Get data for this follow-up period\n",
    "                    period_data = patient_data[\n",
    "                        patient_data[self.period_col] == current_period\n",
    "                    ]\n",
    "                    \n",
    "                    if len(period_data) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    current_treatment = period_data[self.treatment_col].values[0]\n",
    "                    current_outcome = period_data[self.outcome_col].values[0]\n",
    "                    \n",
    "                    # For PP estimand, censor if treatment switches\n",
    "                    is_censored = False\n",
    "                    if self.estimand == \"PP\" and self.expansion_options[\"censor_at_switch\"]:\n",
    "                        if current_treatment != initial_treatment:\n",
    "                            is_censored = True\n",
    "                    \n",
    "                    # Add row to expanded data\n",
    "                    weight = period_data['total_weight'].values[0] if 'total_weight' in period_data else 1.0\n",
    "                    \n",
    "                    expanded_data.append({\n",
    "                        'trial_id': f\"t{trial_period}\",\n",
    "                        self.id_col: patient_id,\n",
    "                        'initial_treatment': initial_treatment,\n",
    "                        'trial_period': trial_period,\n",
    "                        'followup': followup,\n",
    "                        'current_period': current_period,\n",
    "                        'outcome': 0 if is_censored else current_outcome,\n",
    "                        'censored': 1 if is_censored else 0,\n",
    "                        'weight': weight\n",
    "                    })\n",
    "                    \n",
    "                    # Stop follow-up if outcome occurs or censored\n",
    "                    if current_outcome == 1 or is_censored:\n",
    "                        break\n",
    "        \n",
    "        if not expanded_data:\n",
    "            raise ValueError(\"No trials could be constructed from the data\")\n",
    "            \n",
    "        self.expansion = pd.DataFrame(expanded_data)\n",
    "        return self\n",
    "    \n",
    "    def fit_msm(self, max_followup=None):\n",
    "        \"\"\"Fit a marginal structural model to the expanded trials data\"\"\"\n",
    "        if self.expansion is None:\n",
    "            raise ValueError(\"Must expand trials before fitting MSM\")\n",
    "            \n",
    "        expanded_data = self.expansion.copy()\n",
    "        \n",
    "        # Limit to max followup if specified\n",
    "        if max_followup is not None:\n",
    "            expanded_data = expanded_data[expanded_data['followup'] <= max_followup]\n",
    "        \n",
    "        # Prepare data for complementary log-log model\n",
    "        X = sm.add_constant(\n",
    "            pd.DataFrame({\n",
    "                'treatment': expanded_data['initial_treatment'],\n",
    "                'followup': expanded_data['followup']\n",
    "            })\n",
    "        )\n",
    "        y = expanded_data['outcome']\n",
    "        weights = expanded_data['weight']\n",
    "        \n",
    "        # Fit complementary log-log model (approximating Cox model)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            msm_model = sm.GLM(\n",
    "                y, \n",
    "                X, \n",
    "                family=sm.families.Binomial(link=sm.families.links.CLogLog()), \n",
    "                freq_weights=weights\n",
    "            ).fit()\n",
    "        \n",
    "        self.msm = msm_model\n",
    "        return self\n",
    "    \n",
    "    def predict(self, max_followup=None):\n",
    "        \"\"\"Generate predictions based on the fitted MSM\"\"\"\n",
    "        if self.msm is None:\n",
    "            raise ValueError(\"Must fit MSM before generating predictions\")\n",
    "            \n",
    "        # Set max followup if not specified\n",
    "        if max_followup is None:\n",
    "            if self.expansion is not None:\n",
    "                max_followup = self.expansion['followup'].max()\n",
    "            else:\n",
    "                max_followup = 10\n",
    "                \n",
    "        # Create prediction data\n",
    "        pred_data = []\n",
    "        for treatment in [0, 1]:\n",
    "            for followup in range(1, max_followup + 1):\n",
    "                pred_data.append({\n",
    "                    'const': 1,\n",
    "                    'treatment': treatment,\n",
    "                    'followup': followup\n",
    "                })\n",
    "                \n",
    "        pred_df = pd.DataFrame(pred_data)\n",
    "        \n",
    "        # Generate predictions\n",
    "        preds = self.msm.predict(pred_df)\n",
    "        \n",
    "        # Add predictions back to the DataFrame\n",
    "        pred_df['prediction'] = preds\n",
    "        \n",
    "        # Create survival curves\n",
    "        survival_data = []\n",
    "        for treatment in [0, 1]:\n",
    "            # Correctly filter the DataFrame first\n",
    "            treatment_rows = pred_df.loc[pred_df['treatment'] == treatment]\n",
    "            treatment_preds = treatment_rows['prediction']\n",
    "            survival_curve = np.cumprod(1 - treatment_preds.values)\n",
    "            \n",
    "            for i, followup in enumerate(range(1, max_followup + 1)):\n",
    "                survival_data.append({\n",
    "                    'treatment': treatment,\n",
    "                    'followup': followup,\n",
    "                    'survival': survival_curve[i],\n",
    "                    'event_prob': treatment_preds.iloc[i]\n",
    "                })\n",
    "        \n",
    "        self.predictions = pd.DataFrame(survival_data)\n",
    "        return self\n",
    "    \n",
    "    def plot_survival(self):\n",
    "        \"\"\"Plot survival curves for different treatments\"\"\"\n",
    "        if self.predictions is None:\n",
    "            raise ValueError(\"Must generate predictions before plotting\")\n",
    "            \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot for treatment = 0\n",
    "        treat0_data = self.predictions[self.predictions['treatment'] == 0]\n",
    "        plt.plot(treat0_data['followup'], treat0_data['survival'], 'b-', label='Control')\n",
    "        \n",
    "        # Plot for treatment = 1\n",
    "        treat1_data = self.predictions[self.predictions['treatment'] == 1]\n",
    "        plt.plot(treat1_data['followup'], treat1_data['survival'], 'r-', label='Treatment')\n",
    "        \n",
    "        plt.xlabel('Follow-up Time')\n",
    "        plt.ylabel('Survival Probability')\n",
    "        plt.title(f'Survival Curves by Treatment ({self.estimand} Estimand)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Exploration\n",
    "Load trial data and examine its structure. Review key variables including id, period, treatment, outcome, eligible and censored flags, and covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trial data\n",
    "data_censored = pd.read_csv(\"data/data_censored.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data_censored.head()\n",
    "\n",
    "# Review key variables\n",
    "key_variables = ['id', 'period', 'treatment', 'outcome', 'eligible', 'censored', 'x1', 'x2', 'x3', 'x4', 'age', 'age_s']\n",
    "data_censored[key_variables].describe()\n",
    "\n",
    "# Check for missing values in key variables\n",
    "data_censored[key_variables].isnull().sum()\n",
    "\n",
    "# Display the distribution of treatment and outcome variables\n",
    "treatment_distribution = data_censored['treatment'].value_counts(normalize=True)\n",
    "outcome_distribution = data_censored['outcome'].value_counts(normalize=True)\n",
    "\n",
    "treatment_distribution, outcome_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Configuring Trial Sequences\n",
    "Initialize TrialSequence objects for PP and ITT analyses. Set data parameters and configure weight models for treatment switching and censoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trial sequence objects for Per-Protocol (PP) and Intention-to-Treat (ITT) analysis\n",
    "trial_pp = TrialSequence(estimand=\"PP\")\n",
    "trial_itt = TrialSequence(estimand=\"ITT\")\n",
    "\n",
    "# Set data for both trial sequence objects\n",
    "trial_pp = trial_pp.set_data(\n",
    "    data=data_censored,\n",
    "    id=\"id\",\n",
    "    period=\"period\",\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"outcome\",\n",
    "    eligible=\"eligible\"\n",
    ")\n",
    "\n",
    "trial_itt = trial_itt.set_data(\n",
    "    data=data_censored,\n",
    "    id=\"id\",\n",
    "    period=\"period\",\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"outcome\",\n",
    "    eligible=\"eligible\"\n",
    ")\n",
    "\n",
    "# Set up the switch weight model for the Per-Protocol (PP) analysis\n",
    "trial_pp = trial_pp.set_switch_weight_model(\n",
    "    numerator=\"age\",\n",
    "    denominator=\"age + x1 + x3\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=glm_logit()\n",
    ")\n",
    "\n",
    "# Set up the censor weight model for the Per-Protocol (PP) analysis\n",
    "trial_pp = trial_pp.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=glm_logit()\n",
    ")\n",
    "\n",
    "# Set up the censor weight model for the Intention-to-Treat (ITT) analysis\n",
    "trial_itt = trial_itt.set_censor_weight_model(\n",
    "    censor_event=\"censored\",\n",
    "    numerator=\"x2\",\n",
    "    denominator=\"x2 + x1\",\n",
    "    pool_models=\"none\",\n",
    "    model_fitter=glm_logit()\n",
    ")\n",
    "\n",
    "# Display the initialized trial sequence objects\n",
    "print(trial_pp)\n",
    "print(trial_itt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Weights and Expanding Trials\n",
    "Calculate inverse probability weights for both sequences and expand trials into sequential structures with proper follow-up periods and censoring rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights for both trial sequences\n",
    "trial_pp = trial_pp.calculate_weights()\n",
    "trial_itt = trial_itt.calculate_weights()\n",
    "\n",
    "# Display the first few rows of the dataset with calculated weights\n",
    "print(trial_pp.data.head())\n",
    "print(trial_itt.data.head())\n",
    "\n",
    "# Expand trials for both trial sequences\n",
    "trial_pp = trial_pp.expand_trials()\n",
    "trial_itt = trial_itt.expand_trials()\n",
    "\n",
    "# Display the first few rows of the expanded trial data\n",
    "print(trial_pp.expansion.head())\n",
    "print(trial_itt.expansion.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Models and Generating Predictions\n",
    "Fit complementary log-log regression models using the weighted trial data and generate survival predictions for treatment and control groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit MSM for both trial sequences\n",
    "trial_pp = trial_pp.fit_msm(max_followup=8)\n",
    "trial_itt = trial_itt.fit_msm(max_followup=8)\n",
    "\n",
    "# Display the summary of the fitted MSM models\n",
    "print(trial_pp.msm.summary())\n",
    "print(trial_itt.msm.summary())\n",
    "\n",
    "# Generate predictions for both trial sequences\n",
    "trial_pp = trial_pp.predict(max_followup=8)\n",
    "trial_itt = trial_itt.predict(max_followup=8)\n",
    "\n",
    "# Display the first few rows of the predictions\n",
    "print(trial_pp.predictions.head())\n",
    "print(trial_itt.predictions.head())\n",
    "\n",
    "# Plot survival curves for both trial sequences\n",
    "pp_plot = trial_pp.plot_survival()\n",
    "itt_plot = trial_itt.plot_survival()\n",
    "\n",
    "# Display the plots\n",
    "pp_plot.show()\n",
    "itt_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Treatment Effects\n",
    "Plot survival curves for treatment versus control groups to visualize treatment effects over time for both PP and ITT approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot survival curves for both trial sequences\n",
    "pp_plot = trial_pp.plot_survival()\n",
    "itt_plot = trial_itt.plot_survival()\n",
    "\n",
    "# Display the plots\n",
    "pp_plot.show()\n",
    "itt_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing ITT vs PP Analysis\n",
    "Generate side-by-side comparisons of Intention-to-Treat versus Per-Protocol analyses with interpretations of the differences in estimated treatment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract survival data for comparison\n",
    "pp_survival = trial_pp.predictions.pivot(index='followup', columns='treatment', values='survival')\n",
    "itt_survival = trial_itt.predictions.pivot(index='followup', columns='treatment', values='survival')\n",
    "\n",
    "# Plot side-by-side comparison of survival curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot PP survival curves\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(pp_survival.index, pp_survival[0], 'b-', label='Control')\n",
    "plt.plot(pp_survival.index, pp_survival[1], 'r-', label='Treatment')\n",
    "plt.xlabel('Follow-up Time')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Per-Protocol (PP) Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot ITT survival curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(itt_survival.index, itt_survival[0], 'b-', label='Control')\n",
    "plt.plot(itt_survival.index, itt_survival[1], 'r-', label='Treatment')\n",
    "plt.xlabel('Follow-up Time')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.title('Intention-to-Treat (ITT) Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Discuss the differences in estimated treatment effects and their interpretation\n",
    "pp_effect = pp_survival[1] - pp_survival[0]\n",
    "itt_effect = itt_survival[1] - itt_survival[0]\n",
    "\n",
    "# Plot the differences in estimated treatment effects\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pp_effect.index, pp_effect, 'g-', label='PP Effect')\n",
    "plt.plot(itt_effect.index, itt_effect, 'm-', label='ITT Effect')\n",
    "plt.xlabel('Follow-up Time')\n",
    "plt.ylabel('Difference in Survival Probability')\n",
    "plt.title('Comparison of Estimated Treatment Effects (PP vs ITT)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "The Per-Protocol (PP) analysis shows the survival probability for patients who adhered to the treatment protocol, while the Intention-to-Treat (ITT) analysis includes all patients as originally allocated, regardless of adherence. The differences in estimated treatment effects between PP and ITT analyses highlight the impact of treatment adherence on the observed outcomes. The PP analysis typically shows a larger treatment effect due to the exclusion of non-adherent patients, whereas the ITT analysis provides a more conservative estimate that reflects real-world treatment effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostics and Sensitivity Analysis\n",
    "Implement diagnostics for the inverse probability weights and model fit. Compare alternative specification options and assess the robustness of the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the calculated weights to check for extreme values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(trial_pp.data['total_weight'], bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Total Weights (PP)')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(trial_itt.data['total_weight'], bins=50, color='green', alpha=0.7)\n",
    "plt.title('Distribution of Total Weights (ITT)')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Interpretation\n",
    "\n",
    "The sensitivity analysis compares the survival curves obtained from the original and alternative specifications of the weight models. The differences in the survival curves indicate the robustness of the findings to the choice of model specification. If the survival curves are similar, it suggests that the results are robust to the specification of the weight models. If there are substantial differences, it indicates that the findings are sensitive to the model specification, and further investigation is needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
